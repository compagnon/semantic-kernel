{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "99a80181",
            "metadata": {},
            "source": [
                "# Introduction to the Planner\n",
                "\n",
                "The Planner is one of the fundamental concepts of the Semantic Kernel.\n",
                "\n",
                "It makes use of the collection of native and semantic functions that have been registered to the kernel and using AI, will formulate a plan to execute the given ask.\n",
                "\n",
                "From our own testing, planner works best with more powerful models like `gpt4` but sometimes you might get working plans with cheaper models like `gpt-35-turbo`. We encourage you to implement your own versions of the planner and use different models that fit your user needs.\n",
                "\n",
                "Read more about planner [here](https://aka.ms/sk/concepts/planner)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "07eb35d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: semantic-kernel==0.9.6b1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (0.9.6b1)\n",
                        "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.9.5)\n",
                        "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.7.1)\n",
                        "Requirement already satisfied: grpcio>=1.50.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.62.2)\n",
                        "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.1.3)\n",
                        "Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.4.0)\n",
                        "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.6.0)\n",
                        "Requirement already satisfied: numpy>=1.26 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.26.4)\n",
                        "Requirement already satisfied: openai>=1.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.23.6)\n",
                        "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.19.1)\n",
                        "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (23.6.21.0)\n",
                        "Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.9.13)\n",
                        "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2.7.1)\n",
                        "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.0.1)\n",
                        "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2023.12.25)\n",
                        "Requirement already satisfied: scipy>=1.12.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.13.0)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.3.1)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (23.2.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.4.1)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (6.0.5)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.9.4)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel==0.9.6b1) (2.1.5)\n",
                        "Requirement already satisfied: pymongo<5,>=4.5 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (4.7.0)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.3.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (0.27.0)\n",
                        "Requirement already satisfied: sniffio in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.66.2)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.11.0)\n",
                        "Requirement already satisfied: isodate in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.1)\n",
                        "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (4.21.1)\n",
                        "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.3.2)\n",
                        "Requirement already satisfied: more-itertools in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (10.2.0)\n",
                        "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.2)\n",
                        "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.7.1)\n",
                        "Requirement already satisfied: parse in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.20.1)\n",
                        "Requirement already satisfied: werkzeug in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (3.0.2)\n",
                        "Requirement already satisfied: chardet>=3.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (5.2.0)\n",
                        "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.18.6)\n",
                        "Requirement already satisfied: requests>=2.25 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.31.0)\n",
                        "Requirement already satisfied: six~=1.15 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (1.16.0)\n",
                        "Requirement already satisfied: packaging>=21.3 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (24.0)\n",
                        "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic-kernel==0.9.6b1) (0.5.1)\n",
                        "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (0.6.0)\n",
                        "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (2.18.2)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.6b1) (3.7)\n",
                        "Requirement already satisfied: certifi in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (2024.2.2)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (1.0.5)\n",
                        "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (0.14.0)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (2023.12.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.31.1)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.18.0)\n",
                        "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (6.0.1)\n",
                        "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.4.3)\n",
                        "Requirement already satisfied: rfc3339-validator in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.1.4)\n",
                        "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.10.0)\n",
                        "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (2.6.1)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (3.3.2)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.2.1)\n",
                        "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.2.8)\n",
                        "Requirement already satisfied: colorama in c:\\users\\azureuser\\semantic-kernel\\.venv\\lib\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==0.9.6b1) (0.4.6)\n"
                    ]
                }
            ],
            "source": [
                "!python -m pip install -U semantic-kernel==0.9.6b1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "7d548e40",
            "metadata": {},
            "outputs": [],
            "source": [
                "from services import Service\n",
                "\n",
                "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
                "selectedService = Service.AzureOpenAI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "3852961c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel import Kernel  # noqa: F401\n",
                "from semantic_kernel.connectors.ai.open_ai import (  # noqa: F401\n",
                "    AzureChatCompletion,\n",
                "    OpenAIChatCompletion,\n",
                "    OpenAIChatPromptExecutionSettings,\n",
                ")\n",
                "from semantic_kernel.contents import ChatHistory  # noqa: F401\n",
                "from semantic_kernel.functions import KernelArguments  # noqa: F401\n",
                "from semantic_kernel.prompt_template import InputVariable  # noqa: F401\n",
                "from semantic_kernel.utils.settings import (  # noqa: F401\n",
                "    azure_openai_settings_from_dot_env,\n",
                "    openai_settings_from_dot_env,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "11e59885",
            "metadata": {},
            "outputs": [],
            "source": [
                "kernel = Kernel()\n",
                "\n",
                "service_id = None\n",
                "if selectedService == Service.OpenAI:\n",
                "    api_key, org_id = openai_settings_from_dot_env()\n",
                "    service_id = \"default\"\n",
                "    kernel.add_service(\n",
                "        OpenAIChatCompletion(service_id=service_id, ai_model_id=\"gpt-3.5-turbo-1106\", api_key=api_key, org_id=org_id),\n",
                "    )\n",
                "elif selectedService == Service.AzureOpenAI:\n",
                "    deployment, api_key, endpoint = azure_openai_settings_from_dot_env()\n",
                "    service_id = \"default\"\n",
                "    kernel.add_service(\n",
                "        AzureChatCompletion(service_id=service_id, deployment_name=deployment, endpoint=endpoint, api_key=api_key),\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4ff28070",
            "metadata": {},
            "source": [
                "## It all begins with an ask\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "93bc6103",
            "metadata": {},
            "outputs": [],
            "source": [
                "ask = \"\"\"\n",
                "Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\n",
                "Convert the text to uppercase\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a5d86739",
            "metadata": {},
            "source": [
                "### Providing plugins to the planner\n",
                "\n",
                "The planner needs to know what plugins are available to it. Here we'll give it access to the `SummarizePlugin` and `WriterPlugin` we have defined on disk. This will include many semantic functions, of which the planner will intelligently choose a subset.\n",
                "\n",
                "You can also include native functions as well. Here we'll add the TextPlugin.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ca0e7604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.core_plugins import TextPlugin\n",
                "\n",
                "plugins_directory = \"../../samples/plugins/\"\n",
                "summarize_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"SummarizePlugin\")\n",
                "writer_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"WriterPlugin\")\n",
                "text_plugin = kernel.add_plugin(TextPlugin(), \"TextPlugin\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "deff5675",
            "metadata": {},
            "source": [
                "Define your ASK. What do you want the Kernel to do?\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eee6fe7b",
            "metadata": {},
            "source": [
                "# Basic Planner\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "590a22f2",
            "metadata": {},
            "source": [
                "Let's start by taking a look at a basic planner. The `BasicPlanner` produces a JSON-based plan that aims to solve the provided ask sequentially and evaluated in order.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "20d35ed0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.planners import BasicPlanner\n",
                "\n",
                "planner = BasicPlanner(service_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "d5697c09",
            "metadata": {},
            "outputs": [],
            "source": [
                "basic_plan = await planner.create_plan(ask, kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "b425ba1e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "    \"input\": \"Valentine's Day Date Ideas\",\n",
                        "    \"subtasks\": [\n",
                        "        {\"function\": \"WriterPlugin.Brainstorm\"},\n",
                        "        {\"function\": \"WriterPlugin.EmailTo\", \"args\": {\"recipient\": \"significant_other\"}},\n",
                        "        {\"function\": \"WriterPlugin.Translate\", \"args\": {\"language\": \"French\"}},\n",
                        "        {\"function\": \"TextPlugin.uppercase\"}\n",
                        "    ]\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "print(basic_plan.generated_plan)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f3a48f8",
            "metadata": {},
            "source": [
                "You can see that the Planner took my ask and converted it into an JSON-based plan detailing how the AI would go about solving this task, making use of the plugins that the Kernel has available to it.\n",
                "\n",
                "As you can see in the above plan, the AI has determined which functions to call in order to fulfill the user ask. The output of each step of the plan becomes the input to the next function.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cd4df0c2",
            "metadata": {},
            "source": [
                "Let's also define an inline plugin and have it be available to the Planner. Be sure to give it a function name and plugin name.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5057cf9b",
            "metadata": {},
            "source": [
                "Let's update our ask using this new plugin\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a3161dcf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Plugin: SummarizePlugin, Function: MakeAbstractReadable\n",
                        "Plugin: SummarizePlugin, Function: Notegen\n",
                        "Plugin: SummarizePlugin, Function: Summarize\n",
                        "Plugin: SummarizePlugin, Function: Topics\n",
                        "Plugin: WriterPlugin, Function: Acronym\n",
                        "Plugin: WriterPlugin, Function: AcronymGenerator\n",
                        "Plugin: WriterPlugin, Function: AcronymReverse\n",
                        "Plugin: WriterPlugin, Function: Brainstorm\n",
                        "Plugin: WriterPlugin, Function: EmailGen\n",
                        "Plugin: WriterPlugin, Function: EmailTo\n",
                        "Plugin: WriterPlugin, Function: EnglishImprover\n",
                        "Plugin: WriterPlugin, Function: NovelChapter\n",
                        "Plugin: WriterPlugin, Function: NovelChapterWithNotes\n",
                        "Plugin: WriterPlugin, Function: NovelOutline\n",
                        "Plugin: WriterPlugin, Function: Rewrite\n",
                        "Plugin: WriterPlugin, Function: ShortPoem\n",
                        "Plugin: WriterPlugin, Function: StoryGen\n",
                        "Plugin: WriterPlugin, Function: TellMeMore\n",
                        "Plugin: WriterPlugin, Function: Translate\n",
                        "Plugin: WriterPlugin, Function: TwoSentenceSummary\n",
                        "Plugin: WriterPlugin, Function: Shakespeare\n",
                        "Plugin: TextPlugin, Function: lowercase\n",
                        "Plugin: TextPlugin, Function: trim\n",
                        "Plugin: TextPlugin, Function: trim_end\n",
                        "Plugin: TextPlugin, Function: trim_start\n",
                        "Plugin: TextPlugin, Function: uppercase\n"
                    ]
                }
            ],
            "source": [
                "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
                "\n",
                "kernel = Kernel()\n",
                "service_id = \"default\"\n",
                "if selectedService == Service.OpenAI:\n",
                "    api_key, org_id = openai_settings_from_dot_env()\n",
                "    kernel.add_service(\n",
                "        OpenAIChatCompletion(service_id=service_id, ai_model_id=\"gpt-3.5-turbo-1106\", api_key=api_key, org_id=org_id),\n",
                "    )\n",
                "elif selectedService == Service.AzureOpenAI:\n",
                "    deployment, api_key, endpoint = azure_openai_settings_from_dot_env()\n",
                "    kernel.add_service(\n",
                "        AzureChatCompletion(service_id=service_id, deployment_name=deployment, endpoint=endpoint, api_key=api_key),\n",
                "    )\n",
                "\n",
                "plugins_directory = \"../../samples/plugins/\"\n",
                "summarize_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"SummarizePlugin\")\n",
                "writer_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"WriterPlugin\")\n",
                "text_plugin = kernel.add_plugin(TextPlugin(), \"TextPlugin\")\n",
                "\n",
                "shakespeare_func = KernelFunctionFromPrompt(\n",
                "    function_name=\"Shakespeare\",\n",
                "    plugin_name=\"WriterPlugin\",\n",
                "    prompt=\"\"\"\n",
                "{{$input}}\n",
                "\n",
                "Rewrite the above in the style of Shakespeare.\n",
                "\"\"\",\n",
                "    prompt_execution_settings=OpenAIChatPromptExecutionSettings(\n",
                "        service_id=service_id,\n",
                "        max_tokens=2000,\n",
                "        temperature=0.8,\n",
                "    ),\n",
                ")\n",
                "kernel.add_function(\"WriterPlugin\", shakespeare_func)\n",
                "\n",
                "for plugin in kernel.plugins.values():\n",
                "    for function in plugin:\n",
                "        print(f\"Plugin: {plugin.name}, Function: {function.name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "25abac0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "planner = BasicPlanner(service_id)\n",
                "\n",
                "ask = \"\"\"\n",
                "Tomorrow is Valentine's day. I need to come up with a few short poems.\n",
                "She likes Shakespeare so write using his style. She speaks French so write it in French.\n",
                "Convert the text to uppercase.\"\"\"\n",
                "\n",
                "new_plan = await planner.create_plan(goal=ask, kernel=kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "997462e8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "    \"input\": \"Valentine's Day Poems\",\n",
                        "    \"subtasks\": [\n",
                        "        {\"function\": \"WriterPlugin.Brainstorm\"},\n",
                        "        {\"function\": \"WriterPlugin.ShortPoem\"},\n",
                        "        {\"function\": \"WriterPlugin.Shakespeare\"},\n",
                        "        {\"function\": \"WriterPlugin.Translate\", \"args\": {\"language\": \"French\"}},\n",
                        "        {\"function\": \"TextPlugin.uppercase\"}\n",
                        "    ]\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "print(new_plan.generated_plan)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b67a052e",
            "metadata": {},
            "source": [
                "### Executing the plan\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b839c90",
            "metadata": {},
            "source": [
                "Now that we have a plan, let's try to execute it! The Planner has a function called `execute_plan`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "9384831a",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = await planner.execute_plan(new_plan, kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "9192b186",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ASSUREZ-VOUS D'UTILISER UNIQUEMENT LE FRANÇAIS.\n",
                        "\n",
                        "OH, ROSES ROUGES ET VIOLETTES BLEUES,\n",
                        "QUELLE BELLE VUE, COMPARÉE À VOUS.\n",
                        "MAIS SOYONS HONNÊTES, CAR TOUS PEUVENT VOIR,\n",
                        "L'AMOUR EST UNE TOILE COMPLEXE, PAS FACILE À COMPRENDRE.\n",
                        "\n",
                        "CE N'EST PAS SEULEMENT UNE ÉMOTION, MAIS UN ENGAGEMENT,\n",
                        "ADORER QUELQU'UN MALGRÉ SES DÉFAUTS ET SES BORDS.\n"
                    ]
                }
            ],
            "source": [
                "print(results)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8a9b6b7",
            "metadata": {},
            "source": [
                "# The Plan Object Model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e50f8859",
            "metadata": {},
            "source": [
                "To build more advanced planners, we need to introduce a proper Plan object that can contain all the necessary state and information needed for high quality plans.\n",
                "\n",
                "To see what that object model is, look at (https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/plan.py)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0a0cb2a2",
            "metadata": {},
            "source": [
                "# Sequential Planner\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1c66d83",
            "metadata": {},
            "source": [
                "The sequential planner is an XML-based step-by-step planner. You can see the prompt used for it here (https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/sequential_planner/Plugins/SequentialPlanning/skprompt.txt)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "e2e90624",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.planners import SequentialPlanner\n",
                "\n",
                "planner = SequentialPlanner(kernel, service_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "0d537981",
            "metadata": {},
            "outputs": [],
            "source": [
                "sequential_plan = await planner.create_plan(goal=ask)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee2f462b",
            "metadata": {},
            "source": [
                "To see the steps that the Sequential Planner will take, we can iterate over them and print their descriptions\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "e7007418",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Turn a scenario into a short and entertaining poem. : {'execution_settings': {}}\n",
                        "Turn a scenario into a short and entertaining poem. : {'execution_settings': {}}\n",
                        "Turn a scenario into a short and entertaining poem. : {'execution_settings': {}}\n",
                        "None : {'execution_settings': {}}\n",
                        "None : {'execution_settings': {}}\n",
                        "None : {'execution_settings': {}}\n",
                        "Translate the input into a language of your choice : {'execution_settings': {}}\n",
                        "Translate the input into a language of your choice : {'execution_settings': {}}\n",
                        "Translate the input into a language of your choice : {'execution_settings': {}}\n",
                        "Convert a string to uppercase. : {'execution_settings': {}}\n",
                        "Convert a string to uppercase. : {'execution_settings': {}}\n",
                        "Convert a string to uppercase. : {'execution_settings': {}}\n"
                    ]
                }
            ],
            "source": [
                "for step in sequential_plan._steps:\n",
                "    print(step.description, \":\", step._state.__dict__)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4db5f844",
            "metadata": {},
            "source": [
                "Let's ask the sequential planner to execute the plan.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "88411884",
            "metadata": {},
            "outputs": [],
            "source": [
                "result = await sequential_plan.invoke(kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "36d27aa0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ÉCOUTEZ! UNE HISTOIRE D'ÂMES JOYEUSES, DONT LES LANGUES SE SONT DÉLIÉES, ET LA FOLIE A SUIVI. ILS ONT JETÉ LES RÈGLES DU VERS PROPRE, ET ONT PARLÉ AVEC JOIE, POUR FAIRE CONVERSER LA VILLE. LEURS MOTS ONT SONNÉ AVEC RIRE ET DÉLICE, ET BIENTÔT LEUR POÈME A BRILLÉ, UN SPECTACLE SPLENDIDE.\n",
                        "\n",
                        "ALORS PRENEZ GARDE, QUAND VOUS VOUS SENTEZ COINCÉ, ET LAISSEZ VOS MOTS COULER LIBREMENT, SANS QU'UN OISEAU NE LES INTERROMPE. CAR EN L'ABSENCE DE CONTRAINTE, L'ESPRIT FLEURIRA ET L'ÂME S'ÉLÈVERA.\n"
                    ]
                }
            ],
            "source": [
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d6487c75",
            "metadata": {},
            "source": [
                "# Action Planner\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b045e26b",
            "metadata": {},
            "source": [
                "The action planner takes in a list of functions and the goal, and outputs a **single** function to use that is appropriate to meet that goal.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "5bfc0b9f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.planners import ActionPlanner\n",
                "\n",
                "planner = ActionPlanner(kernel, service_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "53b1f296",
            "metadata": {},
            "source": [
                "Let's add more plugins to the kernel\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "cc12642a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "KernelPlugin(name='text', description=None, functions={'lowercase': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='lowercase', plugin_name='text', description='Convert a string to lowercase.', parameters=[KernelParameterMetadata(name='input', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextPlugin.lowercase of TextPlugin()>, stream_method=None), 'trim': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='trim', plugin_name='text', description='Trim whitespace from the start and end of a string.', parameters=[KernelParameterMetadata(name='input', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextPlugin.trim of TextPlugin()>, stream_method=None), 'trim_end': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='trim_end', plugin_name='text', description='Trim whitespace from the end of a string.', parameters=[KernelParameterMetadata(name='input', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextPlugin.trim_end of TextPlugin()>, stream_method=None), 'trim_start': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='trim_start', plugin_name='text', description='Trim whitespace from the start of a string.', parameters=[KernelParameterMetadata(name='input', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextPlugin.trim_start of TextPlugin()>, stream_method=None), 'uppercase': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='uppercase', plugin_name='text', description='Convert a string to uppercase.', parameters=[KernelParameterMetadata(name='input', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextPlugin.uppercase of TextPlugin()>, stream_method=None)})"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from semantic_kernel.core_plugins import MathPlugin, TextPlugin, TimePlugin\n",
                "\n",
                "kernel.add_plugin(MathPlugin(), \"math\")\n",
                "kernel.add_plugin(TimePlugin(), \"time\")\n",
                "kernel.add_plugin(TextPlugin(), \"text\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "b938dc0e",
            "metadata": {},
            "outputs": [],
            "source": [
                "ask = \"What is the sum of 110 and 990?\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "3aafd268",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WriterPlugin.Shakespeare is missing a description\n",
                        "PlannerPlugin.CreatePlan is missing a description\n",
                        "SequentialPlanner_Excluded.SequentialPlanner_Excluded is missing a description\n"
                    ]
                }
            ],
            "source": [
                "plan = await planner.create_plan(goal=ask)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "42589835",
            "metadata": {},
            "outputs": [],
            "source": [
                "result = await plan.invoke(kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "dc75e7a9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1100\n"
                    ]
                }
            ],
            "source": [
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "789b651a",
            "metadata": {},
            "source": [
                "# Stepwise Planner\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8a4bbcc3",
            "metadata": {},
            "source": [
                "Stepwise Planner is based off the paper from MRKL (Modular Reasoning, Knowledge and Language) and is similar to other papers like ReACT (Reasoning and Acting in Language Models). At the core, the stepwise planner allows for the AI to form \"thoughts\" and \"observations\" and execute actions based off those to achieve a user's goal. This continues until all required functions are complete and a final output is generated.\n",
                "\n",
                "See a video walkthrough of Stepwise Planner [here.](https://youtu.be/DG_Ge1v0c4Q?si=T1CHaAm1vV0mWRHu)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e0a00bde",
            "metadata": {},
            "source": [
                "Let's create a Bing Search native plugin that we can pass in to the Kernel.\n",
                "\n",
                "Make sure you have a Bing Search API key in your `.env` file\n",
                "\n",
                "(https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "415f7876",
            "metadata": {},
            "outputs": [
                {
                    "ename": "AssertionError",
                    "evalue": "Bing Search API key not found in .env file",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore_plugins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSearchEnginePlugin\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bing_search_settings_from_dot_env\n\u001b[1;32m----> 5\u001b[0m BING_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[43mbing_search_settings_from_dot_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m connector \u001b[38;5;241m=\u001b[39m BingConnector(BING_API_KEY)\n\u001b[0;32m      7\u001b[0m kernel\u001b[38;5;241m.\u001b[39madd_plugin(WebSearchEnginePlugin(connector), plugin_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebSearch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\azureuser\\semantic-kernel\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\settings.py:202\u001b[0m, in \u001b[0;36mbing_search_settings_from_dot_env\u001b[1;34m()\u001b[0m\n\u001b[0;32m    199\u001b[0m config \u001b[38;5;241m=\u001b[39m dotenv_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m api_key \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBING_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBing Search API key not found in .env file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m api_key\n",
                        "\u001b[1;31mAssertionError\u001b[0m: Bing Search API key not found in .env file"
                    ]
                }
            ],
            "source": [
                "from semantic_kernel.connectors.search_engine import BingConnector\n",
                "from semantic_kernel.core_plugins import WebSearchEnginePlugin\n",
                "from semantic_kernel.utils.settings import bing_search_settings_from_dot_env\n",
                "\n",
                "BING_API_KEY = bing_search_settings_from_dot_env()\n",
                "connector = BingConnector(BING_API_KEY)\n",
                "kernel.add_plugin(WebSearchEnginePlugin(connector), plugin_name=\"WebSearch\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "effdf3ab",
            "metadata": {},
            "source": [
                "Let's also add a couple more plugins\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "abe150e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.core_plugins import MathPlugin, TimePlugin\n",
                "\n",
                "kernel.add_plugin(TimePlugin(), \"time\")\n",
                "kernel.add_plugin(MathPlugin(), \"math\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "06d08549",
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantic_kernel.planners import StepwisePlanner, StepwisePlannerConfig\n",
                "\n",
                "planner = StepwisePlanner(kernel, StepwisePlannerConfig(max_iterations=10, min_iteration_time_ms=1000))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "50699ec3",
            "metadata": {},
            "source": [
                "Now let's do a more complicated ask that will require planner to make a call to Bing to get the latest information.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "596ade21",
            "metadata": {},
            "outputs": [],
            "source": [
                "ask = \"\"\"How many total championships combined do the top 5 teams in the NBA have? And which teams are they?\"\"\"\n",
                "\n",
                "plan = planner.create_plan(goal=ask)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "176988ac",
            "metadata": {},
            "outputs": [],
            "source": [
                "result = await plan.invoke(kernel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d00c6f71",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb40370d",
            "metadata": {},
            "source": [
                "Let's see the steps that the AI took to get to the answer.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7159ca1b",
            "metadata": {},
            "outputs": [],
            "source": [
                "for index, step in enumerate(plan._steps):\n",
                "    print(\"Step:\", index)\n",
                "    print(\"Description:\", step.description)\n",
                "    print(\"Function:\", step.plugin_name + \".\" + step._function.name)\n",
                "    print(f\"  Output: {','.join(str(res) for res in result.metadata['results'])}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
